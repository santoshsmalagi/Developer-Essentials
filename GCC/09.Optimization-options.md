# 9. Optimization options

GCC is an optimizing compiler. It provides a wide range of options to increase the speed and reduce the size of the executables it generates. Optimization is a complex process - for each high-level command in the source code there are usually many possible combinations of machine instructions that can be used to achieve the final result. The compiler must consider these possibilities and choose the best amongst them.

## GCC Optimization levels
In order to control compilation time and compiler memory usage, and the trade-offs between speed and space for the resulting executable, GCC provides a range of general optimization levels, numbered from 0–3, as well as individual options for specific types of optimization. Without any optimization options, the compiler’s goal is to reduce the cost of compilation and to make debugging produce the expected results. Turning on optimization flags makes the compiler attempt to improve the performance and/or code size at the expense of compilation time and possibly the ability to debug the program.  

An optimization level is chosen with the command line option  
``-OLEVEL``, where LEVEL is a number from 0 to 3.

**-O0** (default)  
This is the default. At this optimization level GCC does not perform any optimizations and compiles the source code in the most straightforward way possible. Each command in the source code is converted directly to the corresponding instructions in the executable file, without rearrangement. This is the best option to use when debugging a program. The option ``-O0`` is equivalent to not specifying a ``-O`` option. 

**-Og**  
Optimize debugging experience. ``-Og`` should be the optimization level of choice for the standard edit-compile-debug cycle, offering a reasonable level of optimization while maintaining fast compilation and a good debugging experience.

**-O** or **-O1**  
Optimize. Optimizing compilation takes somewhat more time, and a lot more memory for a large function. This level turns on the most common forms of optimization that do not require any speed-space tradeoffs. With this option the resulting executables should be smaller and faster than with ``-O0``. The more expensive optimizations, such as instruction scheduling, are not used at this level. Compiling with the option ``-O1`` can often take less time than compiling with ``-O0``, due to the reduced amounts of data that need to
be processed after simple optimizations.

**-O2**
This option turns on further optimizations, in addition to those used by ``-O1``. These additional optimizations include instruction scheduling. Only optimizations that do not require any speed-space tradeoffs are used, so the executable should not increase in size. The compiler will take longer to compile programs and require more memory than with ``-O1`` but also increases the performance of the generated executable. This option is generally the best choice for deployment of a program, because it provides maximum optimization
without increasing the executable size.

**-O3**
 ``-O3`` is the highest level of optimization, it turns on more expensive optimizations, such as function inlining, in addition to all the optimizations of the lower levels ``-O2`` and ``-O1``. The ``-O3`` optimization level may increase the speed of the resulting executable, but can also increase its size. Under some circumstances where these optimizations are not favorable, this option might actually make a program slower.
 
 **-funroll-loops**  
This option turns on loop-unrolling, and is independent of the other optimization options. It will increase the size of an executable. Whether or not this option produces a beneficial result has to be examined on a case-by-case basis.

**-Os**  
This option selects optimizations which reduce the size of an executable. The aim of this option is to produce the smallest possible executable, for systems constrained by memory or disk space. In some cases a smaller executable will also run faster, due to better cache usage.

In summary, most optimizations are completely disabled at ``-O0`` or if a ``-O`` level is not set on the command line, even if individual optimization flags are specified. Similarly, ``-Og`` suppresses many optimization passes and ``-O3`` is the highest level of optimization, ``-O2`` suffices for most cases.

> *It is important to remember that the benefit of optimization at the highest levels must be weighed against the cost. The cost of optimization includes greater complexity in debugging, and increased time and memory requirements during compilation. For a complete list of optimization flags refer the gcc manual.*

## Optimization techniques
A few examples of optimization techniques include common sub-expression elimination, function inlining, loop unrolling and scheduling. 

#### Source-level optimizations
The first form of optimization used by GCC occurs at the source-code level and does not require any knowledge of the machine instruction. There are many techniques for source-level optimizations:

* Common subexpression elimination
  * computing an expression in the source code with fewer instructions by reusing already computed results - this rewriting is called common subexpression elimination
  * common subexpression elimination is powerful because it simultaneously increases the speed and reduces the size of the code

* Function inlining
  * increases the efficiency of frequently called functions by avoiding the overhead associated with funciton calls
  * this is achieved by placing the entire function code in place of the function call

#### Speed-space tradeoff
Optimizations with a speed-space tradeoff can also be used to make an executable smaller, at the expense of making it run slower.

* Loop unrolling
    * This form of optimization increases the speed of loops by eliminating the “end of loop” condition on each iteration
    * Since each assignment is independent, it also allows the compiler to use parallelism on processors that support it
    * Loop unrolling is an optimization that increases the speed of the resulting executable but also generally increases its size

#### Scheduling
The lowest level of optimization is scheduling, in which the compiler determines the best ordering of individual instructions
* Many CPUs also support pipelining, where multiple instructions execute in parallel on the same CPU
* When scheduling is enabled, instructions must be arranged so that their results become available to later instructions at the right time, and to allow for maximum parallel execution
* Scheduling improves the speed of an executable without increasing its size, but requires additional memory and time in the compilation process itself (due to its complexity)
